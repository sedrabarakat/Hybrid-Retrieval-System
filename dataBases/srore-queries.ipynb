{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø¥Ø¯Ø®Ø§Ù„ 49 ÙƒÙˆÙŠØ±ÙŠ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© beir.\n",
      "âœ… ØªÙ… Ø¥Ø¯Ø®Ø§Ù„ 2426 ÙƒÙˆÙŠØ±ÙŠ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© antique.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ø£Ø¶Ù Ù…Ø³Ø§Ø± Ù…Ù„Ù corpus.py Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙÙŠ Ù†ÙØ³ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù€ Notebook\n",
    "sys.path.append(\"C:/Users/HP/IR-project\")  # Ø¹Ø¯Ù‘Ù„ Ù‡Ø°Ø§ Ø­Ø³Ø¨ Ù…Ø³Ø§Ø±Ùƒ\n",
    "\n",
    "import mysql.connector\n",
    "from corpus import get_corpus\n",
    "\n",
    "# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ÙƒÙˆÙŠØ±ÙŠØ§Øª\n",
    "def insert_queries(queries_dict, dataset_name):\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"\",\n",
    "        database=\"ir\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS queries (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            query_id VARCHAR(255),\n",
    "            dataset_name VARCHAR(100),\n",
    "            query_text TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    for query_id, query_text in queries_dict.items():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO queries (query_id, dataset_name, query_text) VALUES (%s, %s, %s)\",\n",
    "            (query_id, dataset_name, query_text)\n",
    "        )\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(f\"âœ… ØªÙ… Ø¥Ø¯Ø®Ø§Ù„ {len(queries_dict)} ÙƒÙˆÙŠØ±ÙŠ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© {dataset_name}.\")\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙŠØ±ÙŠØ§Øª\n",
    "beir_queries = get_corpus(\"beir-queries\")\n",
    "antique_queries = get_corpus(\"antique-queries\")\n",
    "\n",
    "# Ø¥Ø¯Ø®Ø§Ù„Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "insert_queries(beir_queries, \"beir\")\n",
    "insert_queries(antique_queries, \"antique\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ù„Ù qrels Ø­ØªÙ‰ Ø§Ù„Ø¢Ù† â€“ ØºÙŠÙ‘Ø± Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯ Ø£Ùˆ ØªØ£ÙƒÙ‘Ø¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Ø­Ø¯Ù‘ÙØ¯ Ø§Ù„Ø¬Ø°Ø± Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ Ù„Ù…Ø´Ø±ÙˆØ¹Ùƒ\n",
    "project_root = Path(r\"C:\\Users\\HP\\IR-project\")          # Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ùˆ Ù…Ø´Ø±ÙˆØ¹Ùƒ ÙÙŠ Ù…ÙƒØ§Ù† Ø¢Ø®Ø±\n",
    "\n",
    "# 2) Ø§Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù…Ù„Ù ÙŠÙ†ØªÙ‡ÙŠ Ø¨Ù€ qrels.tsv Ø£Ùˆ ÙÙŠÙ‡ Ø§Ù„ÙƒÙ„Ù…Ø© qrels\n",
    "qrels_paths = list(project_root.rglob(\"*qrels*.tsv\"))   # Ø¬Ø±Ù‘Ø¨ Ø£ÙŠØ¶Ù‹Ø§ .txt Ø£Ùˆ .jsonl Ø¥Ø°Ø§ Ù„Ø²Ù…\n",
    "\n",
    "if not qrels_paths:\n",
    "    print(\"âŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ù„Ù qrels Ø­ØªÙ‰ Ø§Ù„Ø¢Ù† â€“ ØºÙŠÙ‘Ø± Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯ Ø£Ùˆ ØªØ£ÙƒÙ‘Ø¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "else:\n",
    "    print(\"âœ… Ù…Ù„ÙØ§Øª qrels Ø§Ù„ØªÙŠ ÙˆØ¬Ø¯ØªÙ‡Ø§:\")\n",
    "    for p in qrels_paths:\n",
    "        print(\" -\", p)\n",
    "\n",
    "    # 3) Ø§Ø¹Ø±Ø¶ Ø£ÙˆÙ‘Ù„ Ù…Ù„Ù (Ø£Ùˆ ØºÙŠÙ‘Ø±Ù‡ ÙƒÙ…Ø§ ØªØ±ÙŠØ¯)\n",
    "    qrels_file = qrels_paths[0]\n",
    "    print(\"\\nğŸ“„ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ø®Ù…Ø³Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙÙŠ:\", qrels_file)\n",
    "    df = pd.read_csv(qrels_file, sep=\"\\t\", header=None,\n",
    "                     names=[\"query_id\", \"doc_id\", \"relevance\"])\n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø­ÙØ¸ qrels ÙÙŠ Ø§Ù„Ù…Ù„Ù: beir_qrels.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] opening zip file\n",
      "[INFO] [finished] opening zip file [33ms]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from corpus import get_qrels, save_qrels_to_tsv\n",
    "dataset = \"beir\"\n",
    "qrels = get_qrels(dataset)\n",
    "save_qrels_to_tsv(qrels, f\"{dataset}_qrels.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
